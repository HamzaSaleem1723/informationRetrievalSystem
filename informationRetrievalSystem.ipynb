{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\"/>\n",
    "<img src=\"2.png\"/>\n",
    "<img src=\"3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Creating Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"f1.txt\",\"w\")\n",
    "str1 = \"This is my book\"\n",
    "f1.write(str1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"f2.txt\",\"w\")\n",
    "str2 = \"This is my pen\"\n",
    "f2.write(str2)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open(\"f3.txt\",\"w\")\n",
    "str3 = \"my book is interesting\"\n",
    "f3.write(str3)\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traversing Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have intialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "file_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code starts here   \n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\Hamza\\IRS Directory\"):\n",
    "    for File in files:\n",
    "        if File not in file_dict:\n",
    "            file_dict[File] = 1\n",
    "            file_count = file_count + 1\n",
    "        else:\n",
    "            file_dict[File] = file_dict[File] + 1     \n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 2, 'f2.txt': 2, 'f3.txt': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", file_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extracting Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in files\n",
      " {'my', 'book', 'pen', 'is', 'This', 'interesting'}\n",
      "Count of files  3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "word_list = []\n",
    "for keys in file_dict:\n",
    "    input_file = open(keys,\"r\")\n",
    "    file_content = input_file.read()\n",
    "    word_list  += file_content.split()\n",
    "    input_file.close()\n",
    "unique_word_set = set(word_list)\n",
    "for word in unique_word_set:\n",
    "    if word not in unique_word_set:\n",
    "        unique_word_set.add(word)\n",
    "print(\"Unique words in files\\n\",unique_word_set)\n",
    "print(\"Count of files \", file_count)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Creating Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "# Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Doc Matrix Initially\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Dictionary of unique words\n",
      " {'my': 0, 'book': 1, 'pen': 2, 'is': 3, 'This': 4, 'interesting': 5}\n",
      "\n",
      "Dictionary of files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "term_doc_matrix = np.zeros((file_count, len(unique_word_set)))\n",
    "print(\"Term Doc Matrix Initially\\n\", term_doc_matrix)\n",
    "i = 0\n",
    "word_dict = dict.fromkeys(unique_word_set, 0)\n",
    "for values in word_dict:\n",
    "    word_dict[values] = i\n",
    "    i += 1\n",
    "print (\"\\nDictionary of unique words\\n\", word_dict)\n",
    "j=0\n",
    "file_value_dict = file_dict\n",
    "for values in file_value_dict:\n",
    "    file_value_dict[values] = j\n",
    "    j += 1\n",
    "print(\"\\nDictionary of files\\n\", file_value_dict)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Filling Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "# If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "# Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Doc Matrix after Filling\n",
      " [[1. 1. 0. 1. 1. 0.]\n",
      " [1. 0. 1. 1. 1. 0.]\n",
      " [1. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here \n",
    "for keys in file_value_dict:\n",
    "    word_list2 = []\n",
    "    input_file = open(keys,\"r\")\n",
    "    file_content = input_file.read()\n",
    "    word_list2  += file_content.split()\n",
    "    input_file.close()\n",
    "    for word in word_dict:\n",
    "        if(word in word_list2):\n",
    "            term_doc_matrix[file_value_dict[keys], word_dict[word]] = 1        \n",
    "print(\"Term Doc Matrix after Filling\\n\" , term_doc_matrix)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"6.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Asking for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "user_query_vector_rows = len(word_dict)\n",
    "user_query_vector = np.zeros((user_query_vector_rows,1), dtype = float)\n",
    "print(user_query_vector)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching  This is my book I like it as my book my pen my interesting\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching  \")\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exixts then increment the count of that word in word dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "new_query = query.split(\" \")\n",
    "for word in new_query:\n",
    "    if word in unique_word_set:\n",
    "            user_query_vector[word_dict[word],0] += 1\n",
    "print(user_query_vector)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"8.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Displaying Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.]\n",
      " [7.]\n",
      " [8.]]\n",
      "Maximum in resultant is:  8.0\n",
      "Index of maximum in resultant is:  0\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "resultant = np.dot(term_doc_matrix, user_query_vector)\n",
    "maximum = 0\n",
    "for i in range(0, len(resultant)):\n",
    "    if(resultant[i] > maximum):    \n",
    "        maximum = resultant[i] \n",
    "        index = i\n",
    "print(resultant)\n",
    "print(\"Maximum in resultant is: \", maximum[0])\n",
    "print(\"Index of maximum in resultant is: \", index)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Displaying the contents of file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my book\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "for i in file_dict :\n",
    "    if(file_dict[i] == index):\n",
    "        input_file = open(i,\"r\")\n",
    "        file_content = input_file.read()\n",
    "        input_file.close()\n",
    "print(file_content)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
